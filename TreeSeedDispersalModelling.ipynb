{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "constant-forestry",
   "metadata": {},
   "source": [
    "### Tree Seed Dispersal modelling using ML\n",
    "\n",
    "data: [HF120](https://harvardforest1.fas.harvard.edu/exist/apps/datasets/showData.html?id=HF120)\n",
    "\n",
    "Use regression algorithms to predict distance that each seed travelled from the point at which it was dropped.\n",
    " - height = height in meters at which we dropped each seed (meter) \n",
    " - wind.velocity = wind velocity in meters/second taken with a digital anemometer as we dropped each seed (metersPerSecond)  \n",
    "  \n",
    " - data classification = distance in meters that each seed travelled from the    point at which we dropped it (meter)\n",
    "  \n",
    "  \n",
    "  \n",
    "   \n",
    "  \n",
    "###### Tree Seed Dispersal modelling using Machine Learning \n",
    "Forests are critically important for biodiversity and provide important health and economic benefits. Understanding forests' response to direct mortality resulting from infestation followed by defoliation and indirect mortality in the form of pre-emptive logging is however not very well understood. The efficacy of regeneration of vegetation following hemlock decline depends upon advance regeneration of seedlings and saplings, seed dispersal, and recruitment. In this study, we investigated whether the basic parameters of height of release and wind velocity can be used to model seed dispersal distance in areas both with and without canopies. For modelling, we trained three SVM based machine learning models that allow linear or nonlinear (polynomial and rbf) dependencies. Predicted values of dispersal distance generated by all three models did not provide a good fit to observed dispersal data. Poor fits of the model to the data are likely due to the very small size of the training dataset. Future research should compare model results across open areas  and those with canopies, since it is known that latter diminished the effects of wind and height. More complex models and larger datasets are  necessary to model highly non-linear seed dispersal patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pathlib, shutil, platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['maple', 'oak', 'birch']\n",
    "dataFileRootName=['hf120-01-', 'hf120-02-', 'hf120-03-']\n",
    "dataFileName = [i + j + '.csv' for i, j in zip(dataFileRootName, species)]\n",
    "# myData = [pd.read_csv(str(pathlib.Path('./../data/hrvardf/HF120') / dataFileName)) for f in dataFileName]\n",
    "\n",
    "myData = (pd.concat([(pd.read_csv(str(pathlib.Path('./../data/harvardf/HF120') / f))).assign(spp=spc)\n",
    "                 for f, spc in zip(dataFileName, species)]\n",
    "               ,ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData.shape\n",
    "myData.head(2)\n",
    "myData.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData.info()\n",
    "myData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCols = ['height', 'spp', 'distance']\n",
    "myData[myCols[0]].value_counts(dropna=False) \n",
    "myData[myCols[1]].value_counts(dropna=False)\n",
    "myData[myCols[2]].value_counts(dropna=False)\n",
    "myData.pivot_table(index = [myCols[0]]\n",
    "                   , columns = myCols[1]\n",
    "                   , values =  myCols[2]\n",
    "                   , aggfunc=np.sum, fill_value=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCols = ['height', 'spp', 'wind.velocity']\n",
    "myData[myCols[0]].value_counts(dropna=False) \n",
    "myData[myCols[1]].value_counts(dropna=False)\n",
    "myData[myCols[2]].value_counts(dropna=False)\n",
    "myData.pivot_table(index = [myCols[0]]\n",
    "                   , columns = myCols[1]\n",
    "                   , values =  myCols[2]\n",
    "                   , aggfunc=np.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDataML = myData[myData['spp'].isin(['maple','oak'])]\n",
    "filteredDataML.shape\n",
    "filteredDataML.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "X_data, y_data = (filteredDataML[\"distance\"].values, filteredDataML[\"height\"].values)\n",
    "plt.plot(X_data, y_data, 'ro')\n",
    "plt.suptitle('Graph', y=1.02)\n",
    "plt.ylabel('distance')\n",
    "plt.xlabel('height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = (filteredDataML[['height','wind.velocity']].values, filteredDataML['distance'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(filteredDataML[['height','wind.velocity', 'distance', 'spp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "(filteredDataML[['height','wind.velocity', 'distance', 'spp']]).isnull().sum()\n",
    "\n",
    "# filteredDataML.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, y_data, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Mean squared error (MSE): %.2f'\n",
    "      % metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "print('Coefficient of determination (R^2): %.2f'\n",
    "      % metrics.r2_score(Y_train, Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Coefficient of determination (R^2): %.2f'\n",
    "      % metrics.r2_score(Y_test, Y_pred_test))\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred_test))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(5,11))\n",
    "\n",
    "# 2 row, 1 column, plot 1\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(x=Y_train, y=Y_pred_train, c=\"#7CAE00\", alpha=0.3)\n",
    "\n",
    "# Add trendline\n",
    "# https://stackoverflow.com/questions/26447191/how-to-add-trendline-in-python-matplotlib-dot-scatter-graphs\n",
    "z = np.polyfit(Y_train, Y_pred_train, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(Y_test,p(Y_test),\"#F8766D\")\n",
    "\n",
    "plt.ylabel('Predicted LogS')\n",
    "\n",
    "\n",
    "# 2 row, 1 column, plot 2\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(x=Y_test, y=Y_pred_test, c=\"#619CFF\", alpha=0.3)\n",
    "\n",
    "z = np.polyfit(Y_test, Y_pred_test, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(Y_test,p(Y_test),\"#F8766D\")\n",
    "\n",
    "plt.ylabel('Predicted LogS')\n",
    "plt.xlabel('Experimental LogS')\n",
    "\n",
    "plt.savefig('plot_vertical_logS.png')\n",
    "plt.savefig('plot_vertical_logS.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto')\n",
    "svr_poly = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,\n",
    "               coef0=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "svrs = [svr_rbf, svr_lin, svr_poly]\n",
    "kernel_label = ['RBF', 'Linear', 'Polynomial']\n",
    "\n",
    "model=list()\n",
    "for ix, svr in enumerate(svrs):\n",
    "    model.append(svr.fit(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, svr in enumerate(svrs):\n",
    "#     print(model[ix].support_)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotted_col = 'height'\n",
    "# X_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the results\n",
    "lw = 2\n",
    "plotted_col = 'height'\n",
    "# 'height','wind.velocity'\n",
    "# model.fit(X_train, Y_train)\n",
    "\n",
    "# svrs = [svr_rbf, svr_lin, svr_poly]\n",
    "# kernel_label = ['RBF', 'Linear', 'Polynomial']\n",
    "model_color = ['m', 'c', 'g']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 10), sharey=True)\n",
    "for ix, svr in enumerate(svrs):\n",
    "#     horiz_data = X_train[:,0]\n",
    "    horiz_data = Y_train\n",
    "    axes[ix].scatter(horiz_data, model[ix].predict(X_train), color=model_color[ix], lw=lw,\n",
    "                  label='{} model'.format(kernel_label[ix]))\n",
    "    axes[ix].scatter((horiz_data)[model[ix].support_], Y_train[model[ix].support_], facecolor=\"none\",\n",
    "                     edgecolor=model_color[ix], s=50,\n",
    "                     label='{} support vectors'.format(kernel_label[ix]))\n",
    "#     axes[ix].scatter(X[np.setdiff1d(np.arange(len(X)), svr.support_)],\n",
    "#                      y[np.setdiff1d(np.arange(len(X)), svr.support_)],\n",
    "#                      facecolor=\"none\", edgecolor=\"k\", s=50,\n",
    "#                      label='other training data')\n",
    "    axes[ix].legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "                    ncol=1, fancybox=True, shadow=True)\n",
    "\n",
    "fig.text(0.5, 0.04, 'data', ha='center', va='center')\n",
    "fig.text(0.06, 0.5, 'target', ha='center', va='center', rotation='vertical')\n",
    "fig.suptitle(\"Support Vector Regression\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, svr in enumerate(svrs):\n",
    "    print(str(svr)+':')\n",
    "    Y_pred_test = model[ix].predict(X_test)\n",
    "    print('Coefficient of determination (R^2): %.2f'\n",
    "          % metrics.r2_score(Y_test, Y_pred_test))\n",
    "\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred_test))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-stream",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-reform",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-analysis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-offset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-lotus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-response",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-tenant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
